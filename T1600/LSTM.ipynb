{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cec3755-8638-4fe7-a881-1c31bf1482a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# ✅ Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63841af8-2705-4fac-bb4d-6db74d9958bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset: [10000 10000]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Prepare Data\n",
    "df = pd.read_csv(\"IL_T1600_cleaned.csv\")\n",
    "\n",
    "# Check and drop NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Separate features (X) and label (y)\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Balance the dataset with RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "print(f\"Balanced dataset: {np.bincount(y_resampled)}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab88326-a184-4f85-840b-527bf58e35b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence X_seq shape: (19971, 30, 19)\n",
      "Sequence y_seq shape: (19971,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create Sequences for LSTM\n",
    "timesteps = 30  # Adjusted sequence length\n",
    "\n",
    "def create_sequences(data, labels, seq_len=30):\n",
    "    seqs, labs = [], []\n",
    "    for i in range(len(data) - seq_len + 1):\n",
    "        seqs.append(data[i : i + seq_len])\n",
    "        labs.append(labels[i + seq_len - 1])\n",
    "    return np.array(seqs), np.array(labs)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_resampled, seq_len=timesteps)\n",
    "\n",
    "print(\"Sequence X_seq shape:\", X_seq.shape)\n",
    "print(\"Sequence y_seq shape:\", y_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310f5ca2-0034-480c-99af-ee6359cfee89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (16643, 30, 19) X_test shape: (3328, 30, 19)\n",
      "y_train shape: (16643,) y_test shape: (3328,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: TimeSeriesSplit for Train-Test Split\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X_seq):\n",
    "    X_train, X_test = X_seq[train_index], X_seq[test_index]\n",
    "    y_train, y_test = y_seq[train_index], y_seq[test_index]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape, \"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c2c25a-63db-4651-bc56-7bb3f0d1e4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: Prepare Tensors and DataLoader\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_test_tensor  = torch.tensor(X_test,  dtype=torch.float32).to(device)\n",
    "y_test_tensor  = torch.tensor(y_test,  dtype=torch.long).to(device)\n",
    "\n",
    "batch_size = 32  # Reduced batch size for better gradient updates\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset  = TensorDataset(X_test_tensor,  y_test_tensor)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a658c76-a287-4620-b7bd-acc193f3232b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6: Define LSTM Model\n",
    "class DeeperLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, output_dim=2, num_layers=2, dropout=0.5):\n",
    "        super(DeeperLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_step = lstm_out[:, -1, :]\n",
    "        x = self.fc1(last_step)\n",
    "        x = self.relu(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "num_features = X.shape[1]\n",
    "model = DeeperLSTM(input_dim=num_features).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53be502-b790-4a35-ad0f-dabcabcff04e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Define Weighted Loss and Optimizer\n",
    "class_weights = torch.tensor([0.5, 1.5]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)  # Added L2 regularization\n",
    "\n",
    "print(\"Criterion:\", criterion)\n",
    "print(\"Optimizer:\", optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a86be2-5e47-42af-8262-cd41bc7418af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Loss: 0.6088 | Acc: 40.12%\n",
      "Epoch 2/100 | Loss: 0.3995 | Acc: 78.33%\n",
      "Epoch 3/100 | Loss: 0.3362 | Acc: 83.16%\n",
      "Epoch 4/100 | Loss: 0.3376 | Acc: 83.86%\n",
      "Epoch 5/100 | Loss: 0.2941 | Acc: 85.81%\n",
      "Epoch 6/100 | Loss: 0.2808 | Acc: 86.08%\n",
      "Epoch 7/100 | Loss: 0.2674 | Acc: 86.94%\n",
      "Epoch 8/100 | Loss: 0.2732 | Acc: 87.09%\n",
      "Epoch 9/100 | Loss: 0.2652 | Acc: 87.19%\n",
      "Epoch 10/100 | Loss: 0.2590 | Acc: 87.80%\n",
      "Epoch 11/100 | Loss: 0.2513 | Acc: 87.39%\n",
      "Epoch 12/100 | Loss: 0.2564 | Acc: 87.47%\n",
      "Epoch 13/100 | Loss: 0.2674 | Acc: 87.27%\n",
      "Epoch 14/100 | Loss: 0.2612 | Acc: 87.68%\n",
      "Epoch 15/100 | Loss: 0.2503 | Acc: 87.84%\n",
      "Epoch 16/100 | Loss: 0.2753 | Acc: 87.21%\n",
      "Epoch 17/100 | Loss: 0.2383 | Acc: 88.81%\n",
      "Epoch 18/100 | Loss: 0.2462 | Acc: 88.47%\n",
      "Epoch 19/100 | Loss: 0.2467 | Acc: 88.73%\n",
      "Epoch 20/100 | Loss: 0.2682 | Acc: 87.40%\n",
      "Epoch 21/100 | Loss: 0.2430 | Acc: 88.43%\n",
      "Epoch 22/100 | Loss: 0.2282 | Acc: 89.46%\n",
      "Epoch 23/100 | Loss: 0.2272 | Acc: 89.17%\n",
      "Epoch 24/100 | Loss: 0.2359 | Acc: 88.67%\n",
      "Epoch 25/100 | Loss: 0.2294 | Acc: 89.00%\n",
      "Epoch 26/100 | Loss: 0.2341 | Acc: 89.24%\n",
      "Epoch 27/100 | Loss: 0.2238 | Acc: 89.18%\n",
      "Epoch 28/100 | Loss: 0.2389 | Acc: 88.62%\n",
      "Epoch 29/100 | Loss: 0.2197 | Acc: 89.70%\n",
      "Epoch 30/100 | Loss: 0.2389 | Acc: 88.89%\n",
      "Epoch 31/100 | Loss: 0.2188 | Acc: 89.64%\n",
      "Epoch 32/100 | Loss: 0.2145 | Acc: 89.77%\n",
      "Epoch 33/100 | Loss: 0.2274 | Acc: 89.54%\n",
      "Epoch 34/100 | Loss: 0.2215 | Acc: 89.59%\n",
      "Epoch 35/100 | Loss: 0.2360 | Acc: 89.00%\n",
      "Epoch 36/100 | Loss: 0.2336 | Acc: 88.84%\n",
      "Epoch 37/100 | Loss: 0.2147 | Acc: 89.81%\n",
      "Epoch 38/100 | Loss: 0.2302 | Acc: 89.17%\n",
      "Epoch 39/100 | Loss: 0.2304 | Acc: 89.32%\n",
      "Epoch 40/100 | Loss: 0.2389 | Acc: 88.70%\n",
      "Epoch 41/100 | Loss: 0.2241 | Acc: 89.42%\n",
      "Epoch 42/100 | Loss: 0.2037 | Acc: 90.07%\n",
      "Epoch 43/100 | Loss: 0.2157 | Acc: 89.86%\n",
      "Epoch 44/100 | Loss: 0.2233 | Acc: 89.25%\n",
      "Epoch 45/100 | Loss: 0.2096 | Acc: 89.91%\n",
      "Epoch 46/100 | Loss: 0.2132 | Acc: 89.80%\n",
      "Epoch 47/100 | Loss: 0.2020 | Acc: 90.30%\n",
      "Epoch 48/100 | Loss: 0.2083 | Acc: 89.97%\n",
      "Epoch 49/100 | Loss: 0.2131 | Acc: 90.16%\n",
      "Epoch 50/100 | Loss: 0.2121 | Acc: 89.84%\n",
      "Epoch 51/100 | Loss: 0.2072 | Acc: 89.97%\n",
      "Epoch 52/100 | Loss: 0.2186 | Acc: 89.85%\n",
      "Epoch 53/100 | Loss: 0.2252 | Acc: 89.21%\n",
      "Epoch 54/100 | Loss: 0.2344 | Acc: 89.69%\n",
      "Epoch 55/100 | Loss: 0.2242 | Acc: 89.61%\n",
      "Epoch 56/100 | Loss: 0.2195 | Acc: 89.92%\n",
      "Epoch 57/100 | Loss: 0.2160 | Acc: 89.67%\n",
      "Epoch 58/100 | Loss: 0.1975 | Acc: 90.49%\n",
      "Epoch 59/100 | Loss: 0.2043 | Acc: 90.06%\n",
      "Epoch 60/100 | Loss: 0.2028 | Acc: 90.10%\n",
      "Epoch 61/100 | Loss: 0.2004 | Acc: 90.60%\n",
      "Epoch 62/100 | Loss: 0.2113 | Acc: 90.07%\n",
      "Epoch 63/100 | Loss: 0.2134 | Acc: 90.16%\n",
      "Epoch 64/100 | Loss: 0.2113 | Acc: 90.02%\n",
      "Epoch 65/100 | Loss: 0.2005 | Acc: 90.39%\n",
      "Epoch 66/100 | Loss: 0.2133 | Acc: 90.45%\n",
      "Epoch 67/100 | Loss: 0.1966 | Acc: 90.86%\n",
      "Epoch 68/100 | Loss: 0.2119 | Acc: 90.18%\n",
      "Epoch 69/100 | Loss: 0.2108 | Acc: 90.32%\n",
      "Epoch 70/100 | Loss: 0.1942 | Acc: 90.50%\n",
      "Epoch 71/100 | Loss: 0.1930 | Acc: 91.04%\n",
      "Epoch 72/100 | Loss: 0.2020 | Acc: 90.78%\n",
      "Epoch 73/100 | Loss: 0.2187 | Acc: 89.67%\n",
      "Epoch 74/100 | Loss: 0.1966 | Acc: 90.71%\n",
      "Epoch 75/100 | Loss: 0.2139 | Acc: 90.04%\n",
      "Epoch 76/100 | Loss: 0.1950 | Acc: 90.98%\n",
      "Epoch 77/100 | Loss: 0.2177 | Acc: 90.08%\n",
      "Epoch 78/100 | Loss: 0.2036 | Acc: 90.86%\n",
      "Epoch 79/100 | Loss: 0.1901 | Acc: 91.10%\n",
      "Epoch 80/100 | Loss: 0.2142 | Acc: 90.28%\n",
      "Epoch 81/100 | Loss: 0.2063 | Acc: 90.04%\n",
      "Epoch 82/100 | Loss: 0.1899 | Acc: 91.30%\n",
      "Epoch 83/100 | Loss: 0.2064 | Acc: 90.67%\n",
      "Epoch 84/100 | Loss: 0.2015 | Acc: 90.75%\n",
      "Epoch 85/100 | Loss: 0.2091 | Acc: 90.58%\n",
      "Epoch 86/100 | Loss: 0.2033 | Acc: 90.58%\n",
      "Epoch 87/100 | Loss: 0.1919 | Acc: 90.92%\n",
      "Epoch 88/100 | Loss: 0.1941 | Acc: 90.79%\n",
      "Epoch 89/100 | Loss: 0.1902 | Acc: 91.15%\n",
      "Epoch 90/100 | Loss: 0.2051 | Acc: 90.98%\n",
      "Epoch 91/100 | Loss: 0.2010 | Acc: 91.16%\n",
      "Epoch 92/100 | Loss: 0.2002 | Acc: 90.58%\n",
      "Epoch 93/100 | Loss: 0.1935 | Acc: 91.24%\n",
      "Epoch 94/100 | Loss: 0.1822 | Acc: 91.31%\n",
      "Epoch 95/100 | Loss: 0.1841 | Acc: 91.21%\n",
      "Epoch 96/100 | Loss: 0.1880 | Acc: 91.16%\n",
      "Epoch 97/100 | Loss: 0.1901 | Acc: 91.13%\n",
      "Epoch 98/100 | Loss: 0.2050 | Acc: 90.34%\n",
      "Epoch 99/100 | Loss: 0.1915 | Acc: 90.93%\n",
      "Epoch 100/100 | Loss: 0.1939 | Acc: 90.82%\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Train the Model\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for Xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(Xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += yb.size(0)\n",
    "        correct += (predicted == yb).sum().item()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc  = 100.0 * correct / total\n",
    "    print(f\"Epoch {epoch}/{epochs} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d326f31b-433c-43ff-b8d1-494b0b9e3fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Test Results:\n",
      "Accuracy:   83.65%\n",
      "Precision:  100.00%\n",
      "Recall:     83.65%\n",
      "F1-score:   91.10%\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Evaluate the Model\n",
    "model.eval()\n",
    "all_preds, all_true = [], []\n",
    "with torch.no_grad():\n",
    "    for Xb, yb in test_loader:\n",
    "        logits = model(Xb)\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_true.append(yb.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_true = np.concatenate(all_true)\n",
    "\n",
    "acc  = accuracy_score(all_true, all_preds) * 100\n",
    "prec = precision_score(all_true, all_preds, pos_label=1, zero_division=0) * 100\n",
    "rec  = recall_score(all_true, all_preds, pos_label=1, zero_division=0) * 100\n",
    "f1   = f1_score(all_true, all_preds, pos_label=1, zero_division=0) * 100\n",
    "\n",
    "print(\"\\n✅ Final Test Results:\")\n",
    "print(f\"Accuracy:   {acc:.2f}%\")\n",
    "print(f\"Precision:  {prec:.2f}%\")\n",
    "print(f\"Recall:     {rec:.2f}%\")\n",
    "print(f\"F1-score:   {f1:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537036a-bb35-4ad5-9160-7261e9a44337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
